<div class="page" />

# å¿œç”¨ç·¨

ã“ã“ã‹ã‚‰ã¯ã€å‰åŠéƒ¨åˆ†(ä»¥ä¸‹åˆç´šç·¨ã¨å‘¼ã³ã¾ã™)ã‚’è¸ã¾ãˆ"å¿œç”¨ç·¨"ã¨ã—ã¦ã€æ§‹æˆã‚’å¤‰æ›´ã—ãŸæ§‹é€ åŒ–å‡¦ç†ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã¤ã„ã¦è¨˜è¿°ã—ã¾ã™ã€‚

æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å ´åˆã€ä»¥ä¸‹ã®2ã¤ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

* å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ã‚„ã‚°ãƒ©ãƒ•ä½œæˆãªã©ã‚’ã€å‡¦ç†æ¯ã«åˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡¦ç†ã‚’è¨˜è¿°ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
* è¤‡æ•°ã®ä¼¼ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å‡¦ç†ã‚¯ãƒ©ã‚¹ã¨ã—ã¦è¨˜è¿°ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³

æœ¬ç« ã§ã¯ã€åˆç´šç·¨ã¨åŒã˜å‡¦ç†å†…å®¹ã‚’ã€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ã‚„ã‚°ãƒ©ãƒ•ä½œæˆãªã©ã‚’ã€å‡¦ç†æ¯ã«åˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡¦ç†ã‚’è¨˜è¿°ã—ã€å…¨ä½“ã®è¦‹é€šã—ãŒè‰¯ããªã‚‹ã‚ˆã†ã«æ›¸ãæ›ãˆã¾ã™ã€‚

## æº–å‚™

### RDEToolKit

åˆç´šç·¨ã§ä½¿ç”¨ã—ãŸRDEToolKitã‚’ãã®ã¾ã¾åˆ©ç”¨ã—ã¾ã™ã€‚å¾“ã£ã¦Pythonä»®æƒ³ç’°å¢ƒã®"tenv"ã‚’ãã®ã¾ã¾åˆ©ç”¨ã—ã¾ã™ã€‚

ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹ã«ã—ã¦ã„ãªã„å ´åˆã¯æœ‰åŠ¹ã«ã—ã¾ã™ã€‚

```bash
$ source tenv/bin/activate
(tenv) $
```

### ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ

åˆç´šç·¨ã§ã¯ã€`$HOME/tutorial`ãƒ•ã‚©ãƒ«ãƒ€ã‚’åˆ©ç”¨ã—ã¾ã—ãŸãŒã€å¿œç”¨ç·¨ã§ã¯`$HOME/advanced`ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­ç½®ã™ã‚‹ã“ã¨ã¨ã—ã¾ã™ã€‚

ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€RDEToolKitã®åˆæœŸåŒ–ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

```bash
(tenv) $ cd $HOME

(tenv) $ mkdir advanced
(tenv) $ cd advanced

(tenv) $ python -m rdetoolkit init
Ready to develop a structured program for RDE.
Created: /home/devel/advanced/container/requirements.txt
Created: /home/devel/advanced/container/Dockerfile
Created: /home/devel/advanced/container/data/invoice/invoice.json
Created: /home/devel/advanced/container/data/tasksupport/invoice.schema.json
Created: /home/devel/advanced/container/data/tasksupport/metadata-def.json
Created: /home/devel/advanced/templates/tasksupport/invoice.schema.json
Created: /home/devel/advanced/templates/tasksupport/metadata-def.json
Created: /home/devel/advanced/input/invoice/invoice.json

Check the folder: /home/devel/advanced
Done!
```

### å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«

å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã®sample.dataã€invoice.jsonã€invoice.schema.json ãŠã‚ˆã³ matadata-def.jsonã¯ã€åˆç´šç·¨ã¨åŒã˜ã‚‚ã®ã‚’ä½¿ã†ã®ã§ã€ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

> åˆç´šç·¨ã¨åŒæ§˜ã€æœ¬ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã«ã‚ˆã‚Šä½œæˆã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

```bash
(tenv) $ cd container/

(tenv) $ pwd
/home/devel/advanced/container

(tenv) $ cp $HOME/tutorial/container/data/inputdata/sample.data data/inputdata/
(tenv) $ cp $HOME/tutorial/container/data/invoice/invoice.json data/invoice/
(tenv) $ cp $HOME/tutorial/container/data/tasksupport/invoice.schema.json data/tasksupport/
(tenv) $ cp $HOME/tutorial/container/data/tasksupport/metadata-def.json data/tasksupport/
```

invoice.jsonã‚’ç¢ºèªã—ã€å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€åˆæœŸçŠ¶æ…‹ã«æˆ»ã—ã¾ã™ã€‚

```bash
(tenv) $ vi data/invoice/invoice.json 
```

å¤‰æ›´ç®‡æ‰€ã¯ä»¥ä¸‹ã§ã™ã€‚

å¤‰æ›´å‰

```
        "dataName": "NIMS_TRIAL_20230126b / (2024)",
```

å¤‰æ›´å¾Œ

```
        "dataName": "NIMS_TRIAL_20230126b",
```

> " / (2024)"ãŒè¿½åŠ ã•ã‚Œã¦ã„ãŸã‚‰ã€ãã®éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

### åˆæœŸåŒ–ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

åˆæœŸåŒ–ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚åˆç´šç·¨ã§ä½¿ç”¨ã—ãŸã‚‚ã®ã¨åŒã˜ã‚‚ã®ã‚’åˆ©ç”¨ã™ã‚‹ã®ã§ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚

```bash
(tenv) $ cp $HOME/tutorial/container/reinit.sh .
```

åˆæœŸåŒ–ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸ã«å®Ÿè¡Œã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
```bash
(tenv) $ ./reinit.sh 
./data/logs was removed
./data/meta was removed
./data/main_image was removed
./data/other_image was removed
./data/raw was removed
./data/nonshared_raw was removed
./data/structured was removed
./data/temp was removed
./data/thumbnail was removed
```

### ãƒ™ãƒ¼ã‚¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å¿œç”¨ç·¨ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é…ç½®ã—ã¦ã„ãã¾ã™ã€‚

> ã“ã‚Œã‚‰ã¯NIMSå†…ã§æ¨™æº–çš„ãªã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ãŸã‚‚ã®ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚’åŸºã«æ”¹å¤‰ã—ã¦ã„ãã¾ã™ã®ã§ã€ã“ã“ã§ã¯ä»¥ä¸‹ã®ã¾ã¾ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚
>
> åˆç´šç·¨ã¨åŒæ§˜ã‚³ãƒ¡ãƒ³ãƒˆéƒ¨åˆ†ã¯å‰Šé™¤ã—ã¦ã„ã¾ã™ã€‚

#### modules/inputfile_handler.py

```python
from __future__ import annotations

from pathlib import Path
from typing import Any

import pandas as pd
from rdetoolkit.models.rde2types import MetaType

from modules.interfaces import IInputFileParser


class FileReader(IInputFileParser):

    def read(self, srcpath: Path) -> tuple[MetaType, pd.DataFrame]:
        # Caution! dummy data
        self.data = pd.DataFrame([[1, 11], [2, 22], [3, 33]])
        self.meta: dict[str, str | int | float | list[Any] | bool] = {"meta1": "value1", "meta2": 2}  # Example with int value to match the expected type
        return self.meta, self.data
```

> readãƒ¡ã‚½ãƒƒãƒ‰ã«ã¯ã€ãƒ€ãƒŸãƒ¼å‡¦ç†ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥å¾Œã®å‡¦ç†ã§æ›¸ãæ›ãˆã¦ã„ãã¾ã™ã®ã§ã€ã“ã“ã§ã¯ã“ã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚ä»¥å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚åŒæ§˜ã¨ã—ã¾ã™ã€‚

#### modules/meta_handler.py

```python
from __future__ import annotations

from pathlib import Path
from typing import Any

from rdetoolkit import rde2util
from rdetoolkit.models.rde2types import MetaType, RepeatedMetaType

from modules.interfaces import IMetaParser


class MetaParser(IMetaParser[MetaType]):

    def parse(self, data: MetaType) -> tuple[MetaType, RepeatedMetaType]:
        # dummy return
        self.const_meta_info: MetaType = data
        self.repeated_meta_info: RepeatedMetaType = {"key": ["key_value1", "key_value2"], "sample": ["sample_value1", "sample_value2"]}
        return self.const_meta_info, self.repeated_meta_info

    def save_meta(  # noqa: ANN201
        self,
        save_path: Path,
        metaobj: rde2util.Meta,
        *,
        const_meta_info: MetaType | None = None,
        repeated_meta_info: RepeatedMetaType | None = None,
    ) -> Any:
        if const_meta_info is None:
            const_meta_info = self.const_meta_info
        if repeated_meta_info is None:
            repeated_meta_info = self.repeated_meta_info
        metaobj.assign_vals(const_meta_info)
        metaobj.assign_vals(repeated_meta_info)

        # dummy return
        return metaobj.writefile(str(save_path))
```

#### modules/structured_handler.py

```python
from __future__ import annotations

from pathlib import Path

import pandas as pd

from modules.interfaces import IStructuredDataProcessor


class StructuredDataProcessor(IStructuredDataProcessor):

    def to_csv(self, dataframe: pd.DataFrame, save_path: Path, *, header: list[str] | None = None) -> None:

        if header is not None:
            dataframe.to_csv(save_path, header=header, index=False)
        else:
            dataframe.to_csv(save_path, index=False)
```

#### modules/graph_handler.py

```python
from __future__ import annotations

from pathlib import Path

import pandas as pd

from modules.interfaces import IGraphPlotter


class GraphPlotter(IGraphPlotter[pd.DataFrame]):

    def plot(self, data: pd.DataFrame, save_path: Path, *, title: str | None = None, xlabel: str | None = None, ylabel: str | None = None) -> pd.DataFrame:

        return data  # dummy return value for testing purposes
```

#### modules/interfaces.py

```python
from __future__ import annotations

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Any, Generic, TypeVar

import pandas as pd
from rdetoolkit.models.rde2types import MetaType, RepeatedMetaType
from rdetoolkit.rde2util import Meta

T = TypeVar("T")


class IInputFileParser(ABC):

    @abstractmethod
    def read(self, path: Path) -> Any:  # noqa: D102
        raise NotImplementedError


class IStructuredDataProcessor(ABC):

    @abstractmethod
    def to_csv(self, dataframe: pd.DataFrame, save_path: Path, *, header: list[str] | None = None) -> Any:  # noqa: D102
        raise NotImplementedError


class IMetaParser(Generic[T], ABC):

    @abstractmethod
    def parse(self, data: T) -> Any:  # noqa: D102
        raise NotImplementedError

    @abstractmethod
    def save_meta(
        self, save_path: Path, meta: Meta, *, const_meta_info: MetaType | None = None, repeated_meta_info: RepeatedMetaType | None = None,
    ) -> Any:
        raise NotImplementedError


class IGraphPlotter(Generic[T], ABC):

    @abstractmethod
    def plot(self, data: T, save_path: Path, *, title: str | None = None, xlabel: str | None = None, ylabel: str | None = None) -> Any:  # noqa: D102
        raise NotImplementedError
```

#### modules/datasets_process.py

```python
from rdetoolkit.errors import catch_exception_with_message
from rdetoolkit.models.rde2types import RdeInputDirPaths, RdeOutputResourcePath
from rdetoolkit.rde2util import Meta

from modules.graph_handler import GraphPlotter
from modules.inputfile_handler import FileReader
from modules.meta_handler import MetaParser
from modules.structured_handler import StructuredDataProcessor


class CustomProcessingCoordinator:

    def __init__(
        self,
        file_reader: FileReader,
        meta_parser: MetaParser,
        graph_plotter: GraphPlotter,
        structured_processor: StructuredDataProcessor,
    ):
        self.file_reader = file_reader
        self.meta_parser = meta_parser
        self.graph_plotter = graph_plotter
        self.structured_processor = structured_processor


def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    module = CustomProcessingCoordinator(FileReader(), MetaParser(), GraphPlotter(), StructuredDataProcessor())
    # Read Input File
    meta, df_data = module.file_reader.read(srcpaths.inputdata)
    # Save csv
    module.structured_processor.to_csv(df_data, resource_paths.struct.joinpath("sample.csv"))
    # Meta
    module.meta_parser.parse(meta)
    module.meta_parser.save_meta(resource_paths.meta.joinpath("metadata.json"), Meta(srcpaths.tasksupport.joinpath("metadata-def.json")))
    # Graph
    module.graph_plotter.plot(df_data, resource_paths.main_image.joinpath("sample.png"))


@catch_exception_with_message(error_message="ERROR: failed in data processing", error_code=50)
def dataset(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    custom_module(srcpaths, resource_paths)
```

#### "from __future__ import annotations"ã«ã¤ã„ã¦

ä¸Šè¨˜ã§ç¤ºã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã®1è¡Œç›®ã«ã¯ã€"`from __future__ import annotations`"ã®è¨˜è¿°ãŒã‚ã‚Šã¾ã™ã€‚

`__future__` ã¯Pythonã®æ¨™æº–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã€importã™ã‚‹ã¨Pythonã«æ–°ãŸãªæ§‹æ–‡ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šæ–°ã—ã„Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§è¿½åŠ ã•ã‚ŒãŸæ§‹æ–‡ã‚’ã€å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Pythonã§ã‚‚ã‚¨ãƒ©ãƒ¼ãªãå®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚ã¤ã¾ã‚ŠåŒã˜ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ã€è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³(3.9ã€3.10ãŠã‚ˆã³3.11ãªã©)ã§å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚

> ã™ã¹ã¦ã®å·®ç•°ã‚’å¸åå‡ºæ¥ã‚‹ã‚ã‘ã§ã¯ãªãã€æœ¬æ›¸ã§ã¯ä¸»ã«`å‹ãƒ’ãƒ³ãƒˆ`ã«é–¢ã™ã‚‹è¨˜è¿°ã®å·®ç•°ã‚’å¸åã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

å®Ÿè¡Œã™ã‚‹Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒ"3.10ä»¥é™"ã®ã‚ˆã†ã«ç¢ºå®šå‡ºæ¥ã‚‹å ´åˆã¯ã€ã“ã®è¨˜è¿°ã¯ãªãã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚ä¸è¦ã®å ´åˆã§ã‚‚ä¸å…·åˆã¯ã§ã¾ã›ã‚“ã®ã§ã€æœ¬æ›¸ã§ã¯å…¥ã‚Œã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™ã€‚

> æœ¬æ›¸ã§ä¾‹ç¤ºã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚ã£ã¦ã‚‚ã“ã®è¨˜è¿°ãŒæŠœã‘ã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ãŒPythonãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã®å·®ç•°ã«èµ·å› ã™ã‚‹å ´åˆã¯ã€è¨˜è¿°ã‚’è¿½åŠ ã—ã¦å®Ÿè¡Œã—ã¦ã¿ã¦ãã ã•ã„ã€‚

<div class="page" />

## å®Ÿè£…

åˆç´šç·¨ã§å®Ÿè£…ã—ãŸå†…å®¹ã‚’ã€ãã®ã¾ã¾ä¸Šã®æ§‹æˆã‚’ä½¿ã£ã¦å®Ÿè£…ã—ã¾ã™ã€‚

> å‰è¿°ã®é€šã‚Šã€ä¸Šã§ç”¨æ„ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã«ã¯ãƒ€ãƒŸãƒ¼å‡¦ç†ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ€ãƒŸãƒ¼å‡¦ç†ã¯ä¸Šæ›¸ãã—ã¦ã„ãã¾ã™ã€‚

### main.py

åŸºæœ¬çš„ã«ã€åˆç´šç·¨ã®å®Ÿè£…ã¨å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚

```python
import rdetoolkit

from modules import datasets_process

def main():
    rdetoolkit.workflows.run(
        custom_dataset_function=datasets_process.dataset
    )

if __name__ == '__main__':
    main()
```

å‰ã®ç« ã«ã¦è¨­å®šã—ãŸmodules/dataset_process.pyã«ã¯ãƒ€ãƒŸãƒ¼å‡¦ç†ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã®ã§ã€ã“ã®æ™‚ç‚¹ã§å®Ÿè¡Œã™ã‚‹ã¨ä»¥ä¸‹ã®æ§˜ã«ãªã‚Šã¾ã™ã€‚

æœ€åˆã«å®Ÿè¡Œå‰ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã‚’ç¢ºèªã—ã¾ã™ã€‚

```bash
(tenv) $ tree data
data
â”œâ”€â”€ inputdata
â”‚Â Â  â””â”€â”€ sample.data
â”œâ”€â”€ invoice
â”‚Â Â  â””â”€â”€ invoice.json
â””â”€â”€ tasksupport
    â”œâ”€â”€ invoice.schema.json
    â””â”€â”€ metadata-def.json

4 directories, 4 files
```

å®Ÿè¡Œã—ã€ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã‚’å†åº¦ç¢ºèªã—ã¾ã™ã€‚

```bash
(tenv) $ python main.py 

(tenv) $ tree data
data
â”œâ”€â”€ attachment (â˜…)
â”œâ”€â”€ inputdata
â”‚Â Â  â””â”€â”€ sample.data
â”œâ”€â”€ invoice
â”‚Â Â  â””â”€â”€ invoice.json
â”œâ”€â”€ invoice_patch (â˜…)
â”œâ”€â”€ logs (â˜…)
â”œâ”€â”€ main_image (â˜…)
â”œâ”€â”€ meta (â˜…)
â”œâ”€â”€ nonshared_raw (â˜…)
â”‚Â Â  â””â”€â”€ sample.data (â˜…)
â”œâ”€â”€ other_image (â˜…)
â”œâ”€â”€ raw (â˜…)
â”œâ”€â”€ structured (â˜…)
â”œâ”€â”€ tasksupport
â”‚Â Â  â”œâ”€â”€ invoice.schema.json
â”‚Â Â  â””â”€â”€ metadata-def.json
â”œâ”€â”€ temp (â˜…)
â””â”€â”€ thumbnail (â˜…)

15 directories, 5 files
```

* å®Ÿè¡Œã«ã‚ˆã‚Šã€æ–°è¦ã«ä½œæˆã•ã‚ŒãŸéƒ¨åˆ†ã«"(â˜…)"ã‚’ä»˜ã‘ã¦ã„ã¾ã™ã€‚

> å¿…è¦ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨(æ–°è¦ã«11ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ)ã¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã«å¾“ã„ã€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒ`nonshared_raw/`ã«ã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚

### ç”Ÿãƒ‡ãƒ¼ã‚¿ã®raw/ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®è‡ªå‹•ã‚³ãƒ”ãƒ¼åœæ­¢

RDEToolKitã§ã¯ã€ç”Ÿãƒ‡ãƒ¼ã‚¿( data/inputdata/* )ã¯ã€ä½•ã‚‚æŒ‡å®šã—ãªã„ã¨è‡ªå‹•çš„ã«"data/nonshared_raw"ãƒ•ã‚©ãƒ«ãƒ€(â†’éå…¬é–‹ãƒ•ã‚©ãƒ«ãƒ€)ã«ã‚³ãƒ”ãƒ¼ã•ã‚Œã¾ã™ã€‚

åˆç´šç·¨ã§ç¤ºã—ãŸã‚ˆã†ã«ã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§æ˜ç¤ºçš„ã«è¡Œã†ãŸã‚ã€è‡ªå‹•ã‚³ãƒ”ãƒ¼ã‚’åœæ­¢ã—ã¾ã™ã€‚

è‡ªå‹•ã‚³ãƒ”ãƒ¼ã®åœæ­¢ã¯ã€`"main.py"ã®ä¸­ã§è¨­å®šã™ã‚‹`æ–¹æ³•ã¨ã€`è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã£ã¦è¨­å®šã™ã‚‹`æ–¹æ³•ã®2ã¤ã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚

main.pyã®ä¸­ã§è¨­å®šã™ã‚‹æ–¹æ³•ã¯åˆç´šç·¨å†…ã§ã‚„ã‚Šã¾ã—ãŸã®ã§ã€å¿œç”¨ç·¨ã§ã¯ã€"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"ã‚’ç½®ãã“ã¨ã§åŒæ§˜ã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚

ä»¥ä¸‹ã®å†…å®¹ã§ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

data/tasksupport/rdeconfig.yaml

```yaml
system:
    save_raw: False
    save_nonshared_raw: False
```

> è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã†å ´åˆã€"main.py"å†…ã§è¨­å®šå†…å®¹ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"main.py"å†…ã§è¨­å®šã‚’è¡Œã£ãŸå ´åˆã¯ä¸Šè¨˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯**åˆ©ç”¨ã•ã‚Œã¾ã›ã‚“**ã€‚
>
> è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€`rdeconfig.yaml`ã®ä»–ã€`rdeconfig.yml`ã‚„`pyproject.toml`ãŒåˆ©ç”¨ã§ãã¾ã™ã€‚
>
> RDEToolKitå†…ã§ã¯ã€main.pyå†…ã®è¨­å®š â†’ rdeconfig.yaml â†’ rdeconfig.yml â†’ pyproject.tomlã®é †ã«ç¢ºèªã—ã€æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®**ã ã‘**ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

ä¸Šè¨˜è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­ç½®å¾Œã€ãã‚Œã¾ã§ã®å®Ÿè¡Œã§å‡ºåŠ›ã•ã‚ŒãŸå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã€å†åº¦å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚

```bash
(tenv) $ ./reinit.sh 
:

(tenv) $ python main.py 
(tenv) $ tree data
data
â”œâ”€â”€ attachment
â”œâ”€â”€ inputdata
â”‚Â Â  â””â”€â”€ sample.data
â”œâ”€â”€ invoice
â”‚Â Â  â””â”€â”€ invoice.json
â”œâ”€â”€ invoice_patch
â”œâ”€â”€ logs
â”‚Â Â  â””â”€â”€ rdesys.log
â”œâ”€â”€ main_image
â”œâ”€â”€ meta
â”‚Â Â  â””â”€â”€ metadata.json
â”œâ”€â”€ nonshared_raw
â”œâ”€â”€ other_image
â”œâ”€â”€ raw
â”œâ”€â”€ structured
â”‚Â Â  â””â”€â”€ sample.csv
â”œâ”€â”€ tasksupport
â”‚Â Â  â”œâ”€â”€ invoice.schema.json
â”‚Â Â  â”œâ”€â”€ metadata-def.json
â”‚Â Â  â””â”€â”€ rdeconfig.yaml
â”œâ”€â”€ temp
â””â”€â”€ thumbnail

15 directories, 8 files
```

> `data/nonshared_raw/`"ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚‚ã€`data/raw/`ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚‚ã€ç”Ÿãƒ‡ãƒ¼ã‚¿(â†’ data/inputdata/* )ãŒã‚³ãƒ”ãƒ¼ã•ã‚Œã¦**ã„ãªã„**ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚

### modules/datasets_process.pyã‹ã‚‰ä½™è¨ˆãªå‡¦ç†ã‚’å‰Šé™¤

å…ˆã«ç¤ºã—ãŸdatasets_process.pyã«ã¯ã€ãƒ€ãƒŸãƒ¼å‡¦ç†ã¨ã—ã¦ä¸å¿…è¦ãªå‡¦ç†ãŒå¤šãè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã®ã§ã€å‡¦ç†ã‚’è¨˜è¿°ã™ã‚‹å‰ã«å‰Šé™¤ã—ã¾ã™ã€‚

å…·ä½“çš„ã«ã¯ã€"custom_module():"å†…ã®è¨˜è¿°ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã™ã€‚

```python
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    pass

```

> ãƒ¡ã‚½ãƒƒãƒ‰(é–¢æ•°)å†…ã«å‡¦ç†ãŒãªã„ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã®ã§ã€ä½•ã‚‚å®Ÿè¡Œã—ãªã„`pass`ã ã‘ã‚’è¨˜è¿°ã—ã¾ã™ã€‚å¾Œè¿°ã™ã‚‹å‡¦ç†ã‚’è¿½è¨˜ã—ãŸå ´åˆã¯ã€ä¸è¦ã¨ãªã‚Šã¾ã™ã®ã§ã€å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚

ã“ã®çŠ¶æ…‹ã§`python main.py`ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ä»¥å‰åŒæ§˜å‡ºåŠ›ç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã™ã€‚

```bash
(tenv) $ python main.py 

(tenv) $ tree data
data
â”œâ”€â”€ attachment
â”œâ”€â”€ inputdata
â”‚Â Â  â””â”€â”€ sample.data
â”œâ”€â”€ invoice
â”‚Â Â  â””â”€â”€ invoice.json
â”œâ”€â”€ invoice_patch
â”œâ”€â”€ logs
â”‚Â Â  â””â”€â”€ rdesys.log
â”œâ”€â”€ main_image
â”œâ”€â”€ meta
â”œâ”€â”€ nonshared_raw
â”œâ”€â”€ other_image
â”œâ”€â”€ raw
â”œâ”€â”€ structured
â”œâ”€â”€ tasksupport
â”‚Â Â  â”œâ”€â”€ invoice.schema.json
â”‚Â Â  â”œâ”€â”€ metadata-def.json
â”‚Â Â  â””â”€â”€ rdeconfig.yaml
â”œâ”€â”€ temp
â””â”€â”€ thumbnail

15 directories, 6 files
```

### ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æº–å‚™

å„ç¨®å‡¦ç†ã‚’è¨˜è¿°ã™ã‚‹éš›ã«åˆ©ç”¨ã™ã‚‹ã¨ä¾¿åˆ©ãªã‚¯ãƒ©ã‚¹ã‚’ã¾ã¨ã‚ãŸ`CustomProcessingCoordinator`ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”¨æ„ã—ã¾ã™ã€‚

modules/datasets_process.py

```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    coordinator = CustomProcessingCoordinator(FileReader(), MetaParser(), GraphPlotter(), StructuredDataProcessor())
ï¼š
```

> å¤‰æ›´å‰ã¯ã€"module"ã¨ã„ã†å¤‰æ•°ã‚’ç”¨ã„ã¦ã„ã¾ã—ãŸãŒã€pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ ¼ç´å ´æ‰€ãŒ`modules/`ã§ã‚ã‚Šã€åŒºåˆ¥ãŒä»˜ã‘ã«ãã„ã®ã§ã€æœ¬æ›¸ã§ã¯å¤‰æ•°ã¨ã—ã¦`coordinator`ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
>
> ä½•ã‚‚å®Ÿè¡Œã—ãªã„ã¨ã„ã†æ„å‘³ã§"pass"ã‚’è¨˜è¿°ã—ã¦ã„ãŸå ´åˆã¯ã€å‰Šé™¤ã—ã¾ã™ã€‚

ä¸Šè¨˜çŠ¶æ…‹ã§ä¿å­˜ã—ã¦ã€æ¬¡ã«é€²ã¿ã¾ã™ã€‚

### å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯

å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯éƒ¨åˆ†ã‚’inputfile_handler.pyã«å®Ÿè£…ã—ã¾ã™ã€‚

modules/inputfile_handler.py

```python
ï¼š
from rdetoolkit.errors import StructuredError
ï¼š
class FileReader(IInputFileParser):
    ï¼š
    def check(self, srcpaths: Path) -> bool:
        # Check input file
        input_dir = srcpaths.inputdata
        input_files = list(input_dir.glob("*"))

        if len(input_files) == 0:
            raise StructuredError("ERROR: input data not found")

        if len(input_files) > 1:
            raise StructuredError("ERROR: input data should be one file")

        raw_file_path = input_files[0]
        if raw_file_path.suffix.lower() != ".data":
            raise StructuredError(
                f"ERROR: input file is not '*.data' : {raw_file_path.name}"
            )

        return True
```
> é–¢æ•°åŒ–ã«ä¼´ã„ã€æœ€å¾Œã«"return True"ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚çœŸå½å€¤ã®æˆ»ã‚Šå€¤ãŒæœŸå¾…ã•ã‚Œã¾ã™ãŒã€Trueä»¥å¤–ã®å ´åˆã¯ã€raiseå‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€False(å½)ãŒè¿”ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚åŒæ§˜ã«raiseå‡¦ç†ãŒå®Ÿè¡Œã•ã‚ŒãŸå ´åˆã¯ã€ãã‚Œä»¥é™ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã®ã§ã€elseå¥ã§ã†ã‘ã‚‹å¿…è¦ã‚‚ãªã„ã®ã§ã€ã“ã“ã§ã¯ã€elif/elseå¥ã‚’ä½¿ã‚ãªã„å½¢ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
>
> readãƒ¡ã‚½ãƒƒãƒ‰ã«ã¤ã„ã¦ã¯å¾Œã§ä¿®æ­£ã—ã¾ã™ã®ã§ã€ã“ã®æ™‚ç‚¹ã§ã¯å¤‰æ›´ã—ã¾ã›ã‚“ã€‚

å‘¼ã³å‡ºã—å´(modules/datasets_process.py)ã®æ–¹ã‚’å¤‰æ›´ã—ã¾ã™ã€‚

```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Check input file
    coordinator.file_reader.check(srcpaths)
ï¼š
```

ç”Ÿãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€æ§‹é€ åŒ–å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚

```bash
(tenv) $ cat data/inputdata/sample.data
[METADATA]
data_title=data_title 2
measurement_date=2023/1/25 23:08
:

(tenv) $ python main.py 
(tenv) $ 
```

å•é¡Œç„¡ãçµ‚äº†ã—ã¾ã—ãŸã€‚

ç¶šã„ã¦ã€ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’è©¦ã—ã¾ã™ã€‚

```bash
(tenv) $ touch data/inputdata/test.data

(tenv) $ python main.py

Traceback (simplified message):
Call Path:
   File: /home/devel/tenv/lib/python3.12/site-packages/rdetoolkit/errors.py, Line: 43 in wrapper()
    â””â”€ File: /home/devel/advanced/container/modules/datasets_process.py, Line: 35 in dataset()
        â””â”€ File: /home/devel/advanced/container/modules/datasets_process.py, Line: 30 in custom_module()
            â””â”€ File: /home/devel/advanced/container/modules/inputfile_handler.py, Line: 24 in check()
                â””â”€> L24: raise StructuredError("ERROR: input data should be one file") ğŸ”¥

Exception Type: StructuredError
Error: ERROR: input data should be one file
```

> ã€Œå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1å€‹ã ã‘ã‚ã‚‹ã€ã¨ã„ã†å‰æãŒå´©ã‚Œã¦ã„ã‚‹ãŸã‚ã€æƒ³å®šé€šã‚Šã‚¨ãƒ©ãƒ¼ã¨ãªã‚Šã¾ã™ã€‚

ç¢ºèªãŒã™ã¿ã¾ã—ãŸã®ã§ã€å…ˆã»ã©ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¶ˆã—ã¾ã™ã€‚

```bash
(tenv) $ rm data/inputdata/test.data
(tenv) $ tree data/inputdata
data/inputdata
â””â”€â”€ sample.data

1 directory, 1 file
```

å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ã®å†…å®¹ã¯åˆç´šç·¨ã¨åŒã˜ã§ã™ã®ã§ã€ä»–ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®ç¢ºèªã¯çœç•¥ã—ã¾ã™ã€‚

### invoice.jsonã®èª­ã¿è¾¼ã¿ã¨ä¿å­˜

invoice.jsonã‚’æ‰±ã†ã‚¯ãƒ©ã‚¹ã‚’**æ–°è¦ã«**ä½œæˆã—ã¾ã™ã€‚

modules/invoice_handler.py

```python
from pathlib import Path

from rdetoolkit.core import DirectoryOps
from rdetoolkit.invoicefile import InvoiceFile


class InvoiceParser(InvoiceFile):
    """RDE invoice.json handle
    """

    def __init__(self, invoiceFile):
        super().__init__(invoiceFile)

    @property
    def is_private_raw(self) -> bool:
        invoice_dict = self.invoice_obj
        # Check private or not
        custom = invoice_dict.get("custom")
        if custom is None:
            return False
        is_private_raw = custom.get("is_private_raw")
        if is_private_raw == "share":
            return False
        # other case -> "private"
        return True

    def change_title(self):
        # Update invoice title
        original_data_name = self.invoice_obj["basic"]["dataName"]
        additional_title = "(2024)"
        if original_data_name.find(additional_title) < 0:
            # update title if not applied yet
            self.invoice_obj["basic"]["dataName"] = \
                original_data_name + " / " + additional_title
            # Overwrite
            invoice_file_new = self.invoice_path
            self.overwrite(invoice_file_new)

    def backup(self):
        # Backup(=Copy) invoice.json to shared/nonshared folder
        is_private_raw = self.is_private_raw
        invoice_file = self.invoice_path
        ops = DirectoryOps("data")
        if is_private_raw:
            raw_dir = ops.nonshared_raw.path
        else:
            raw_dir = ops.raw.path
        invoice_file_backup = Path(raw_dir) / "invoice.json.orig"
        InvoiceFile.copy_original_invoice(invoice_file, invoice_file_backup)
```

> ä¸Šä½(datasetes_process.pyã®dataset()é–¢æ•°ã€ã‚‚ã—ãã¯custom_module()é–¢æ•°)ã§åˆ©ç”¨ã—ã¦ã„ãŸå¤‰æ•°`resource_paths`ã¯ã“ã“ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã®ã§ã€DirectoryOpsã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¦é©åˆ‡ãªãƒ•ã‚©ãƒ«ãƒ€åã‚’å–å¾—ã—ã¦ã„ã¾ã™ã€‚å®Ÿè¡Œæ™‚ã®å¼•æ•°ã¨ã—ã¦resource_pathsã‚’è¿½åŠ ã—ã¦ã€æœ¬å‡¦ç†ã®ä¸­ã§ã¯ã€ãã‚Œã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ã€‚
>
> ä»¥å‰ã®RDEToolKit(v1.0.4ä»¥å‰)ã§ã¯ã€`StorageDir`ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¦ã„ã¾ã—ãŸã€‚v1.1.0ã§ã¯ã¾ã `StorageDir`ã‚¯ãƒ©ã‚¹ã‚’åˆ©ç”¨ã§ãã¾ã™ãŒã€ä»Šå¾Œã¯ã€`DirectoryOps`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚(æœ¬ä»¶ã¯ä»Šå¾Œå¤‰æ›´ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šä»Šå¾Œã‚‚StorageDirã‚¯ãƒ©ã‚¹ã‚’ç¶™ç¶šã—ã¦ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚)

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚

```python
ï¼š
from modules.invoice_handler import InvoiceParser
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    coordinator = CustomProcessingCoordinator(FileReader(), MetaParser(), GraphPlotter(), StructuredDataProcesser())

    # Check input file
    coordinator.file_reader.check(srcpaths)

    # Read and Update Invoice
    invoice_file = srcpaths.invoice / 'invoice.json'
    invoice = InvoiceParser(invoice_file)
    invoice.backup()
    invoice.change_title()
ï¼š
```

> å®Ÿè¡Œã™ã‚‹é †ç•ªã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚invoice.jsonã®å¤‰æ›´ã‚’å®Ÿæ–½ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã®å‰ã«backupãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œã—ãªã„ã¨ã€å¤‰æ›´å¾Œã®å†…å®¹ã‚’"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

main.pyã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```bash
(tenv) $ python main.py
(tenv) $ tree
ï¼š
â”‚Â Â  â”œâ”€â”€ nonshared_raw
â”‚Â Â  â”‚Â Â  â””â”€â”€ invoice.json.orig
:
(tenv) $ diff -ru data/nonshared_raw/invoice.json.orig data/invoice/invoice.json 
--- data/nonshared_raw/invoice.json.orig        2025-05-08 08:34:19.863414308 +0000
+++ data/invoice/invoice.json   2025-05-08 08:34:19.864414308 +0000
@@ -3,7 +3,7 @@
     "basic": {
         "dateSubmitted": "2023-01-26",
         "dataOwnerId": "119cae3d3612df5f6cf7085fb8deaa2d1b85ce963536323462353734",
-        "dataName": "NIMS_TRIAL_20230126b",
+        "dataName": "NIMS_TRIAL_20230126b / (2024)",
         "instrumentId": "413e53fb-aec9-41f8-ae55-3f88f6cd8d41",
         "experimentId": null,
         "description": ""
```

æ¬¡ã®å‡¦ç†ã«å‚™ãˆã€ä¸Šã§å‡ºåŠ›ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ãªã©ã€å®Ÿè¡Œå‰ã®çŠ¶æ…‹ã«æˆ»ã—ã¦ãŠãã¾ã™ã€‚

```bash
(tenv) $ ./reinit.sh
ï¼š
```

> æœ¬æ¥ã¯ã€invoice.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã«æˆ»ã—ãŸæ–¹ãŒã‚ˆã„ã§ã™ãŒã€å¤§ããªå½±éŸ¿ã¯ãªã„ãŸã‚ã€ã“ã“ã§ã¯ãã®ã¾ã¾æ”¹å¤‰å¾Œã®invoice.jsonã‚’å…¥åŠ›å€¤ã¨ã—ã¦æ‰±ã†ã“ã¨ã«ã—ã¾ã™ã€‚

### å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

ç¶šã„ã¦ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€å‡¦ç†ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

> ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹readãƒ¡ã‚½ãƒƒãƒ‰å‡¦ç†ã¯å‰Šé™¤ã—ã¦ã‹ã‚‰ã€ä¸Šã®è¨˜è¿°ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

modules/inputfile_handler.py

```python
import io
ï¼š
    def read(self, srcpaths: Path) -> tuple[MetaType, list[pd.DataFrame]]:
        # Read input data
        DELIM = "="
        rawDataDf = None
        rawMetaObj = None
        #
        input_dir = srcpaths.inputdata
        input_file = input_dir / "sample.data"

        with open(input_file) as f:
            lines = f.readlines()
        # omit new line codes (\r and \n)
        lines_strip = [line.strip() for line in lines]

        meta_row = [i for i, line in enumerate(lines_strip) if "[METADATA]" in line]
        data_row = [i for i, line in enumerate(lines_strip) if "[DATA]" in line]
        if (meta_row != []) & (data_row !=[]):
            meta = lines_strip[(meta_row[0]+1):data_row[0]]
            # metadata to dict
            raw_meta_obj = dict(map(lambda x: tuple([x.split(DELIM)[0],
                        DELIM.join(x.split(DELIM)[1:])]), meta))
        else:
            raise StructuredError("ERROR: invalid RAW METADATA or DATA")

        # read data to data.frame
        if (int(raw_meta_obj["series_number"])!= len(data_row)):
            raise StructuredError("ERROR: unmatch series number")
        raw_data_df = []
        for i in data_row:
            series_name = lines_strip[i+1]
            cnt = int(lines_strip[i+2])
            csv = "".join(lines[(i+3):(i+3+cnt)])
            temp_df = pd.read_csv(io.StringIO(csv),header=None)
            temp_df.columns = ["x", series_name]
            raw_data_df.append(temp_df)
        #
        return raw_meta_obj, raw_data_df
```

> æˆ»ã‚Šå€¤ã®å‹ãƒ’ãƒ³ãƒˆéƒ¨åˆ†ã‚‚å¤‰æ›´ã•ã‚Œã¾ã™ã€‚`tuple[MetaType, pd.DataFrame]` â†’ `tuple[MetaType, list[pd.DataFrame]]`

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚

```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Read input data
    meta, df_data = coordinator.file_reader.read(srcpaths)

ï¼š
```

pprintãªã©ã‚’ä½¿ã£ã¦å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã¨ä»¥ä¸‹ã®æ§˜ã«ãªã£ã¦ã„ã¾ã™ã€‚

meta
```
{'data_title': 'data_title 2',
 'measurement_date': '2023/1/25 23:08',
 'series_number': '3',
 'x_label': 'x(unit)',
 'y_label': 'y(unit)'}
```

df_data
```
[       x  series1
0    1.0    101.0
1    2.0    102.0
2    3.0    103.0
3    4.0    104.0
4    5.0    105.0
5    6.2    106.0
6    7.0      NaN
7    8.0    108.0
8    9.5    109.0
9   10.0    101.0
10  11.0    103.0
11  12.0    105.0
12  13.0    104.0
13  14.0    100.0
14  15.0     98.0
15  16.0     82.0,
      x  series2
0    1      101
1    2      102
2    3      103
3    4      104
4    5      105
5    6      106
6    9      109
7   10       90
8   12       60
9   13       52
10  14       41,
        x  series3
0    1.0    101.0
1    1.5    101.2
2    2.0    102.0
3    3.0    103.0
4    4.0    104.0
5    5.0    105.0
6    6.0    106.0
7    9.0    109.0
8   10.0     90.0
9   12.0     60.0
10  13.0     52.0
11  14.0     41.0]
```

### ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›

ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨å‡ºåŠ›ã‚’å®Ÿè£…ã—ã¾ã™ã€‚åŸºæœ¬çš„ãªãƒ­ã‚¸ãƒƒã‚¯ã¯ã€åˆç´šç·¨ã¨åŒã˜ã§ã™ã€‚

> ã‚‚ã¨ã‚‚ã¨ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦å®Ÿè£…ã•ã‚Œã¦ã„ãŸéƒ¨åˆ†ã¯ã»ã¨ã‚“ã©ä½¿ã„ã¾ã›ã‚“ã€‚ä¸‹è¨˜ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚

modules/meta_handler.py

```python
from __future__ import annotations

from pathlib import Path
from typing import Any
import statistics as st

from rdetoolkit import rde2util
from rdetoolkit.models.rde2types import MetaType, RepeatedMetaType

from modules.interfaces import IMetaParser


class MetaParser(IMetaParser[MetaType]):

    def __init__(self):
        self.const_meta_info = dict()
        self.repeated_meta_info = dict()

    def parse_from_invoice(self, invoice) -> None:
        # Merge invoice info to meta
        if invoice["custom"] is not None:
            self.const_meta_info = self.const_meta_info | invoice["custom"]

    def parse_from_inputdata(self, meta, data) -> None:

        # From meta
        self.const_meta_info = self.const_meta_info | meta

        # From raw data numeric data part
        s_name = []
        s_count = []
        s_mean = []
        s_median = []
        s_max = []
        s_min = []
        s_stdev = []

        for df in data:
            d = df.dropna(axis=0)
            y = d.iloc[:, 1]
            s_name.append(d.columns[1])
            s_count.append(len(y))
            s_mean.append("{:.2f}".format(st.mean(y)))
            s_median.append("{:.2f}".format(st.median(y)))
            s_max.append(max(y))
            s_min.append(min(y))
            s_stdev.append("{:.2f}".format(st.stdev(y)))

        metaVars = {
            "series_name": s_name,
            "series_data_count": s_count,
            "series_data_mean": s_mean,
            "series_data_median": s_median,
            "series_data_max": s_max,
            "series_data_min": s_min,
            "series_data_stdev": s_stdev,
        }

        # Set variable meta
        self.repeated_meta_info = metaVars

    def parse(self, data: MetaType) -> tuple[MetaType, RepeatedMetaType]:
        #
        return self.const_meta_info, self.repeated_meta_info

    def save_meta(
        self,
        save_path: Path,
        metaobj: rde2util.Meta,
        *,
        const_meta_info: Optional[MetaType] = None,
        repeated_meta_info: Optional[RepeatedMetaType] = None
    ):
        """
        Save parsed metadata to a file using the provided Meta object
        """

        if const_meta_info is None:
            const_meta_info = self.const_meta_info
        if repeated_meta_info is None:
            repeated_meta_info = self.repeated_meta_info
        metaobj.assign_vals(const_meta_info)
        metaobj.assign_vals(repeated_meta_info)

        metaobj.writefile(save_path)
```

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚

```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Read input data
    meta, df_data = coordinator.file_reader.read(srcpaths)

    # Meta  (â€»ã“ã“ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹)
    coordinator.meta_parser.parse_from_invoice(invoice.invoice_obj)
    coordinator.meta_parser.parse_from_inputdata(meta, df_data)
    coordinator.meta_parser.save_meta(
        resource_paths.meta.joinpath("metadata.json"),
        Meta(srcpaths.tasksupport.joinpath("metadata-def.json"))
    )
ï¼š
```

### ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å¯èª­åŒ–

ç¶šã„ã¦ã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å¯èª­åŒ–ã€ã¤ã¾ã‚Šã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã™ã‚‹éƒ¨åˆ†ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

modules/structured_handler.py

```python
from __future__ import annotations

from pathlib import Path

import pandas as pd

from modules.interfaces import IStructuredDataProcessor


class StructuredDataProcessor(IStructuredDataProcessor):

    def to_csv(self, dataframes: list[pd.DataFrame], save_path: Path, *, header: list[str] | None = None) -> None:
        # Write CSV file(s)
        for d in dataframes:
            fname = d.columns[1].replace(" ", "") + ".csv"
            csvFilePath = save_path / fname
            if header is not None:
                d.to_csv(csvFilePath, header=header, index=False)
            else:
                d.to_csv(csvFilePath, header=True, index=False)
```

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚

```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Read input data
    meta, df_data = coordinator.file_reader.read(srcpaths)
:
    # Save csv  (â€»ã“ã“ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹)
    coordinator.structured_processor.to_csv(df_data, resource_paths.struct)

ï¼š
```

### ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–

å¯èª­åŒ–ã«ç¶šãã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

modules/graph_handler.py

```python
from __future__ import annotations

from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt

from modules.interfaces import IGraphPlotter


class GraphPlotter(IGraphPlotter[pd.DataFrame]):

    def plot(self, data: list[pd.DataFrame], save_path: Path, *, title: Optional[str] = None, xlabel: str | None = None, ylabel: str | None = None):
        # Write Graph
        title = title if title is not None else "No title"
        xlabel = xlabel if xlabel is not None else "X-label"
        ylabel = ylabel if ylabel is not None else "Y-label"

        ## by series
        for d in data:
            x = d.iloc[:, 0]
            y = d.iloc[:, 1]
            label = d.columns[1]
            fname = save_path.other_image / f"{label}.png"
            fig, ax = plt.subplots(figsize=(5, 5), facecolor="white")
            ax.plot(x, y, label=label)
            ax.set_title(title)
            ax.set_xlabel(xlabel)
            ax.set_ylabel(ylabel)
            ax.legend()
            fig.savefig(fname)
            plt.close(fig)

        ## all series
        fig, ax = plt.subplots(figsize=(5, 5), facecolor="lightblue")
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        ax.set_title(title)
        for d in data:
            x = d.iloc[:, 0]
            y = d.iloc[:, 1]
            label = d.columns[1]
            ax.plot(x, y, label=label)
        ax.legend()
        fname = save_path.main_image / "all_series.png"
        fig.savefig(fname)
        plt.close(fig)
```

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚
```python
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Read input data
    meta, df_data = coordinator.file_reader.read(srcpaths)
:
    # Graph  (â€»ã“ã“ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹)
    const_meta_info = coordinator.meta_parser.const_meta_info
    coordinator.graph_plotter.plot(
        df_data,
        resource_paths,
        title=const_meta_info["data_title"],
        xlabel=const_meta_info["x_label"],
        ylabel=const_meta_info["y_label"]
    )

ï¼š
```

### ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã®ä½œæˆ

ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’æ‰±ã†ã‚¯ãƒ©ã‚¹ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã›ã‚“ã®ã§ã€æ–°è¦ã«ä½œæˆã—ã¾ã™ã€‚

åŸºç¤ç·¨ã®ã‚ˆã†ã«ã€ç‹¬è‡ªã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã‚‚ã‚ˆã„ã§ã™ãŒã€RDEToolKit v1.0.2ã‚ˆã‚Šã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒä½œæˆã«åˆ©ç”¨å‡ºæ¥ãã†ãªé–¢æ•°ãŒè¿½åŠ ã«ãªã£ãŸã®ã§ã€ã“ã“ã§ã¯ãã‚Œã‚’ä½¿ã£ã¦ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’ã¤ãã‚Šã¾ã™ã€‚

modules/thumbnail_handler.py

```python
from __future__ import annotations

from pathlib import Path

from rdetoolkit.models.rde2types import RdeOutputResourcePath
from rdetoolkit.img2thumb import resize_image


class ThumbnailDrawer():

    def draw(self, resource_paths: RdeOutputResourcePath) -> None:
        # Write thumbnail images
        src_img_file_path = resource_paths.main_image / "all_series.png"
        out_img_file_path = resource_paths.thumbnail / "thumbnail.png"

        # Size of thumbnail
        closure_w = 286
        closure_h = 200

        resize_image(
            src_img_file_path,
            closure_w,
            closure_h,
            out_img_file_path
        )
```

ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«"modules/datasets_process.py"ã«è¿½åŠ ã—ã¾ã™ã€‚

```python
ï¼š
from modules.thumbnail_handler import ThumbnailDrawer
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Graph
    const_meta_info = coordinator.meta_parser.const_meta_info
    coordinator.graph_plotter.plot(
        df_data,
        resource_paths,
        title=const_meta_info["data_title"],
        xlabel=const_meta_info["x_label"],
        ylabel=const_meta_info["y_label"]
    )
    ï¼š
    # Thumbnail  (â€»ã“ã“ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹)
    thumbnail = ThumbnailDrawer()
    thumbnail.draw(resource_paths)
ï¼š
```

> ã‚°ãƒ©ãƒ•ç”»åƒã‚’ã‚‚ã¨ã«ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’ä½œæˆã—ã¾ã™ã®ã§ã€ã‚°ãƒ©ãƒ•ç”»åƒç”Ÿæˆã®å¾Œã«å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
>
> ã¾ãŸã€åŸºç¤ç·¨ã§ã®ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒä½œæˆã¨ã¯ã“ã¨ãªã‚Šã€ç¸¦æ¨ªæ¯”ã®èª¿æ•´ãªã©ã¯è¡Œã£ã¦ã„ãªã„ãŸã‚ã€ä¸Šè¨˜å®Ÿè£…ã§ã¯ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã®å·¦å³ç«¯ã«ç™½è‰²å¸¯ãŒä½œæˆã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€ä½œæˆã•ã‚Œã‚‹ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã®ç¸¦æ¨ªã‚µã‚¤ã‚ºè¨­å®šã‚’å¤‰æ›´ã™ã‚‹ã‹ã€åŸºç¤ç·¨ã§ã®å®Ÿè£…ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚

### ç”Ÿãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–

è¨­å®šã«ã‚ˆã‚Šç”Ÿãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–(nonshared_rawã¾ãŸã¯rawãƒ•ã‚©ãƒ«ãƒ€ã¸ã®è‡ªå‹•ã‚³ãƒ”ãƒ¼)ã‚’æŠ‘æ­¢ã—ã¾ã—ãŸã®ã§ã€æ°¸ç¶šåŒ–å‡¦ç†ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

> åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦åˆ‡ã‚Šå‡ºã™ã»ã©ã®ãƒ­ã‚¸ãƒƒã‚¯ã§ã¯ãªã„ã®ã§ã€datasets_process.pyã«ç›´æ¥è¨˜è¿°ã™ã‚‹ã“ã¨ã«ã—ã¾ã™ã€‚

modules/datasets_process.py

```python
ï¼š
import shutil
ï¼š
def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:
    ï¼š
    # Copy inputdata to public (raw/) or non_public (nonshared_raw/)
    is_private_raw = invoice.is_private_raw
    raw_dir = resource_paths.nonshared_raw if is_private_raw else resource_paths.raw
    input_dir = srcpaths.inputdata
    input_file = input_dir / "sample.data"
    shutil.copy(input_file, raw_dir)
```

> invoice.jsonã®è¨­å®šå†…å®¹ã‚’ä½¿ã„ã¾ã™ã®ã§ã€invoiceã®å‡¦ç†ã®ã‚ã¨ã«è¨˜è¿°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ã¾ã¨ã‚

ä¸Šè¨˜ã®æ§˜ãªè¨˜è¿°ã‚’è¡Œã†ã“ã¨ã«ã‚ˆã‚Šã€custom_module()é–¢æ•°å†…ã®è¨˜è¿°ãŒã™ã£ãã‚Šã—ã¾ã™ã€‚

å¿µã®ãŸã‚ã€æœ€çµ‚çš„ãªmodules/datasets_process.pyã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚

```python
import shutil

from rdetoolkit.errors import catch_exception_with_message
from rdetoolkit.models.rde2types import RdeInputDirPaths, RdeOutputResourcePath
from rdetoolkit.rde2util import Meta

from modules.graph_handler import GraphPlotter
from modules.inputfile_handler import FileReader
from modules.meta_handler import MetaParser
from modules.structured_handler import StructuredDataProcessor
from modules.invoice_handler import InvoiceParser
from modules.thumbnail_handler import ThumbnailDrawer

class CustomProcessingCoordinator:

    def __init__(
        self,
        file_reader: FileReader,
        meta_parser: MetaParser,
        graph_plotter: GraphPlotter,
        structured_processor: StructuredDataProcessor,
    ):
        self.file_reader = file_reader
        self.meta_parser = meta_parser
        self.graph_plotter = graph_plotter
        self.structured_processor = structured_processor


def custom_module(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    coordinator = CustomProcessingCoordinator(FileReader(), MetaParser(), GraphPlotter(), StructuredDataProcessor())

    # Check input file
    coordinator.file_reader.check(srcpaths)

    # Read and Update Invoice
    invoice_file = srcpaths.invoice / 'invoice.json'
    invoice = InvoiceParser(invoice_file)
    invoice.backup()
    invoice.change_title()

    # Read input data
    meta, df_data = coordinator.file_reader.read(srcpaths)
    """
    from pprint import pprint
    pprint(meta)
    print("=======")
    pprint(df_data)
    """
    # Meta
    coordinator.meta_parser.parse_from_invoice(invoice.invoice_obj)
    coordinator.meta_parser.parse_from_inputdata(meta, df_data)
    coordinator.meta_parser.save_meta(
        resource_paths.meta.joinpath("metadata.json"),
        Meta(srcpaths.tasksupport.joinpath("metadata-def.json"))
    )

    # Save csv
    coordinator.structured_processor.to_csv(df_data, resource_paths.struct)

    # Graph
    const_meta_info = coordinator.meta_parser.const_meta_info
    coordinator.graph_plotter.plot(
        df_data,
        resource_paths,
        title=const_meta_info["data_title"],
        xlabel=const_meta_info["x_label"],
        ylabel=const_meta_info["y_label"]
    )

    # Thumbnail
    thumbnail = ThumbnailDrawer()
    thumbnail.draw(resource_paths)

    # Copy inputdata to public (raw/) or non_public (nonshared_raw/)
    is_private_raw = invoice.is_private_raw
    raw_dir = resource_paths.nonshared_raw if is_private_raw else resource_paths.raw
    input_dir = srcpaths.inputdata
    input_file = input_dir / "sample.data"
    shutil.copy(input_file, raw_dir)

@catch_exception_with_message(error_message="ERROR: failed in data processing", error_code=50)
def dataset(srcpaths: RdeInputDirPaths, resource_paths: RdeOutputResourcePath) -> None:

    custom_module(srcpaths, resource_paths)
```

> CustomProcessingCoordinatorã«ã€InvoiceParserã‚¯ãƒ©ã‚¹ã€ThumbnailDrawerã‚¯ãƒ©ã‚¹ã‚’è¿½è¨˜ã—ãŸæ–¹ãŒã‚ˆã‚Šã‚ˆã„ã‚‚ã®ã«ãªã‚‹ã‹ã‚‚ã—ã¾ã›ã‚“ãŒã€æœ¬ç« ã§ã¯ã“ã“ã¾ã§ã«ã—ã¦ãŠãã¾ã™ã€‚

